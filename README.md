## <sup><span id="QU7qfmzQ0c"></span>Key Features</sup>

-   **Parallel background job management**. Uses SQL Server’s native
    Message Queues and Service Broker to manage measurement tasks as
    parallel background jobs, in conjunction with SQL Server Agent for
    scheduling.

-   **Point-in-time history**: Uses SQL Server’s native Temporal
    “System-Versioned” table features to allow detailed progress
    reporting while minimising storage requirements.

-   **Simple measure management**: Creating measures is simple and
    flexible, with embedded XML metadata for portability.

-   **XML report generation**: Outputs XML formatted reporting and case
    lists for consumption directly into BI and reporting software, for
    storage as a file.

-   **Single script setup**: Uses a single “bootstrap script” to deploy
    into a SQL server. No file management required.

-   **Built-in source code management**: Maintains its own code
    repository within the database

-   **Easy redeployment across environments**: Generates a bootstrap
    script for the current environment, on demand.

-   **Email notifications**: Uses SQL Server’s native DB Mail to deliver
    notifications of changes to case lists and internal errors.

## <sup><span id="anNNzfof3O"></span>Installation</sup>

TDQ is installed using a “Bootstrap Script”. A Bootstrap Script can be
generated by executing the Pack Procedure, which produces a Bootstrap
Script as messages output.

The Bootstrap Script can then be executed on any database. There are two
variables that could be altered first:

-   <sup>@SchemaName: All TDQ objects will be created in this schema,
    except the Service Broker Service “BatchScheduler”. It’s recommended
    TDQ objects are isolated in their own schema, but dbo is an
    acceptable schema if this cannot be done.</sup>

-   <sup> @Prefix: A prefix to the object name. All objects will have
    this text prefixed to their name. It’s not necessary to prefix TDQ
    objects if they are in their own schema, so an empty string is
    acceptable.</sup>

<sup>Objects will take the name
\[{@SchemaName}\].\[{@Prefix}{ObjectName}\]</sup>

<sup>Examples:</sup>

|             |         |                  |
|-------------|---------|------------------|
| @SchemaName | @Prefix | Object Name      |
| ‘tdq’       | ‘‘      | tdq.Measures     |
| ‘dbo’       | 'tdq\_‘ | dbo.tdq_Measures |
| ‘dbo’       | ‘dq’    | dbo.dqMeasures   |
|             |         |                  |

<sup>Once the variables have been set, the Bootstrap Script can be
executed. This is detailed in the design section under
</sup>**<sup>Bootstrap Script Procedure</sup>**<sup>.</sup>

## <sup><span id="mFpqiOjZof"></span>Configuration</sup>

TDQ is configured using the Box Table. Objects with the ObjectType
‘CONF’ contain configuration values.

## <sup><span id="G9k5KXEo5x"></span>Email</sup>

### <sup><span id="a2E1zqfVPs"></span>Templates</sup>

TDQ supports parameterised email templates to simplify core code and
allow customisation of the messaging. The EmailSend Procedure can take
an Box Table Object Name as a parameter. The Object Name must correspond
to an configuration object in the Box table with a text content value,
otherwise the procedure will exit in error. The text content is parsed
as follows:

-   <sup>$PARAMETERn$ (where n is 1 to 5): Replaced with supplied
    @Parameter1 to @Parameter5 values.</sup>

-   <sup>\\n\\r, \\n, \\r replaced with CRLF’s (in that order)</sup>

-   <sup>\\t replaced with tab characters</sup>

-   <sup>Above can all be escaped with a \\ (e.g. \\$PARAMETER1$ or
    \\\\n).</sup>

-   <sup>Note that any instance of a double backslash \\\\ will be
    substituted with a single backslash \\</sup>

## <sup><span id="ZndEiWv7Zw"></span>Design</sup>

### <sup><span id="tT2UU1nWYI"></span>Add a Measure</sup>

Create a view with the following pattern:

<sup>`CREATE OR ALTER VIEW [``{``HomeSchema``}``].[``{``HomePrefix``}``{``MeasureViewPattern``}``]``{``unique token``}`` AS`</sup>

<sup>`/*``<measure>`</sup>

<sup>` <id>``{``uniqueidentifier``}``</id>`</sup>

<sup>` <code>``{``Measure Code``}``</code>`</sup>

<sup>` <description>``{``Description of measure.``}``</description>`</sup>

<sup>` <refreshPolicy>``{``Continuous|Hourly|Daily|Mo|Tu|We|Th|Fr|Sa|Su``}``</description>`</sup>

<sup>` <refreshTimeOffset>``{``HH:mm``}``</description>`</sup>

<sup>`</measure>``*/`</sup>

<sup>`SELECT Colum``n`</sup>

<sup>`FROM Table`</sup>

<sup>`WHERE Column=Value;`</sup>

<sup>Where in the name of the view:</sup>

-   <sup>{`HomeSchema``}`, {`HomePrefix``}` and {`MeasureViewPattern``}`
    are the configuration parameters in the Box table.</sup>

    -   <sup>NOTE!: The schema, and the name of the view should be
        encapsulated with square brackets, such as \[schema\].\[full
        name of view\]. This is not strictly required for TSQL, but is
        expected by TDQ.</sup>

<!-- -->

-   <sup>{`unique token``}` is anything that makes the view name unique,
    such as the Measure Code, but it doesn’t matter to TDQ what this is
    because it is based on the embedded XML metadata.</sup>

<sup>Take special note of the XML embedded in a comment. This is
metadata that is required by TDQ:</sup>

-   <sup>{`uniqueidentifier`} stands for a GUID to track the measure
    even if the Measure Code changes. Use may the TSQL function NEWID()
    to generate one.</sup>

-   <sup>{`Measure Code``}` stands for the unique organisation
    meaningful measure code</sup>

-   <sup>{`Description of measure.``}` stands for a organisation
    meaningful description of the data quality problem identified by the
    measure.</sup>

-   <sup>refreshPolicy and refreshTimeOffset control the frequency and
    timing at which measurements are taken.</sup>

**<sup>NOTE!</sup>**<sup>: tags are </sup>**<sup>CASE
SENSITIVE</sup>**<sup>.</sup>

#### <sup><span id="GwCMoRRKBo"></span>Refresh Policy</sup>

The Refresh Policy and Refresh Time Offset control when a measurement
job will be scheduled.

|                            |                       |                                                                                                                |
|----------------------------|-----------------------|----------------------------------------------------------------------------------------------------------------|
| Refresh Policy             | Time Offset Meaning   | Description                                                                                                    |
| Hourly                     | Minutes past the hour | A new measurement will be taken each hour, but no earlier than the number of minutes past the hour.            |
| Daily                      | Time of day           | A new measurement will be taken each day, but no earlier than the time of day                                  |
| Mo, Tu, We, Th, Fr, Sa, Su | Time of day           | A new measurement will be taken once a week on the given day, no earlier than the given time of day.           |
| Continuous                 | Minimum wait time     | A new measurement will be taken once the time since the last measurement is greater than the minimum wait time |
|                            |                       |                                                                                                                |

<sup>Typical scenarios</sup>

|                                                                                                                                                                                                                                                                                      |                |             |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------|-------------|
| Scenario                                                                                                                                                                                                                                                                             | Refresh Policy | Time Offset |
| Measurement is taken on a production data copy that is refreshed overnight. The measurement should be taken after source data refresh before business hours.                                                                                                                         | Daily          | 06:00       |
| Measurement is taken from a production copy of a particularly large source data is only refreshed on the weekend. Measurement should be taken early in the morning to ensure it’s ready before business hours.                                                                       | Monday         | 03:00       |
| Measurement is taken on a data warehouse that is progressively refreshed multiple times a day, and frequent quality measurement is desired. To ensure a load of jobs do not stack up on the hour, the measurement refresh should be delayed until at least 15 minutes after the hour | Hourly         | 00:15       |
| Measurement is taken on a near real-time copy of production                                                                                                                                                                                                                          | Continuous     | 00:30       |
| A measurement should be taken at least every 12 hours, regardless of the time of day.                                                                                                                                                                                                | Continuous     | 12:00       |
|                                                                                                                                                                                                                                                                                      |                |             |

<sup>NOTE:</sup>

<sup>The Refresh policies Hour, Daily, and Mon-Sun do not “catch up”. If
they miss their opportunity to run. Examples:</sup>

-   <sup>With Policy = Daily and Offset = 23:30, if the server was
    rebooted just before 11:30pm and did not completely start up until
    after 12am, the window has closed. The next measurement attempt
    would be after 11:30pm..</sup>

-   <sup>With Policy = Sun and Offset = 03:00, if the measurement was
    returning an error which was not resolved until Monday, the
    measurement would not be reattempted until the following Sunday
    morning.</sup>

-   <sup>With Policy = Hourly and Offset = 00:45: If the Agent only runs
    every 30 minutes then the measurement will never be taken because
    the check will be performed at 30 minutes past the hour too early,
    then again on the hour which is too late for last hour and too early
    for the current hour</sup>

<sup>Also note that with Policy = Hourly, if the Offset is greater than
an hour such as 01:15, the measurement can never occur because this
means “One hour and fifteen minutes past the hour”.</sup>

<sup>By contrast, the Continuous policy always “catches up”. Regardless
of when exactly the last refresh is, as it was at least as long ago as
the Offset, measurement will be reattempted.</sup>

### <sup><span id="7jd1UyBiEc"></span>Main Loop</sup>

The main loop of TDQ is as follows:

1.  <sup>The SQL Server Agent triggers the Schedule procedure</sup>

2.  <sup>The Schedule procedure uses the Measures view and Measurements
    table, along with rules in the Box table to adds measures to the
    MeasurementJobs queue</sup>

    1.  <sup>Technically this is done by starting a “Conversation” on
        the TDQScheduler service</sup>

    2.  <sup>Each Measurement Job is a “Message” which gets added to the
        MeasurementJobs </sup>

<!-- -->

1.  <sup>When an measure is added to the MeasurementJobs queue, the
    RefreshNext procedure is fired</sup>

    1.  <sup>The RefreshFromQueue procedure takes the next job off the
        queue and fires the Refresh procedure</sup>

### <sup><span id="O482af7b4C"></span>Refresh Procedure</sup>

1.  Selects the view into a temporary table

2.  Merges the temporary table into the Cases table

## <sup><span id="yg0Z3OrGe1"></span></sup>

### <sup><span id="wd4ijao6l7"></span>Bootstrap Script</sup>

This creates the TDQ framework in the following steps:

1.  <sup>Sets the @SchemaName and @Prefix variables. These are where TDQ
    will be installed.</sup>

2.  <sup>If the Box Table already exists, throws an error</sup>

3.  <sup>Creates a temporary table #BoxTable and puts all the TDQ
    objects into it</sup>

4.  <sup>Locates the Box Table create script in #BoxTable and runs
    it</sup>

5.  <sup>Inserts the content of #BoxTable into the Box Table</sup>

6.  <sup>Locates the Unpack Procedure create script in #BoxTable and
    runs it</sup>

7.  <sup>Executes the Unpack Procedure</sup>

<sup>The Unpack Procedure locates all create scripts in the Box Table
(Object Types CODE, TABL and MESR) and runs them one by one. Scripts
with the autoExecute tag in their XML metadata will also have their
procedure executed (E.g., Batch Config Procedure and Agent Config
Procedure).</sup>

## <sup><span id="1fejzs3UTi"></span>Comparison to “DQ-in-a-Box” (DQB)</sup>

<table>
<tbody>
<tr class="odd">
<td><p>DQB Concept</p></td>
<td><p>TDQ Concept</p></td>
<td><p>Commentary</p></td>
</tr>
<tr class="even">
<td><p>Measure</p></td>
<td><p>Measure</p></td>
<td><p>Conceptually the same, although measures in TDQ are all views. Additionally, there is no prescribed column layout in TDQ.</p></td>
</tr>
<tr class="odd">
<td><p>Run Steps</p></td>
<td><p>Measurement</p></td>
<td><p>DQB’s run steps table gave a count history for measures, similar to TDQ’s Measurement table.</p>
<p>Semantically, TDQ refers to the activity of searching for data quality issues as “taking a measurement”, compared to DQB’s “running a measure”.</p></td>
</tr>
<tr class="even">
<td><p>Results</p></td>
<td><p>Cases</p></td>
<td><p>Conceptually analogous.</p>
<p>However in TDQ, the Cases Table is a Temporal Table (aka “System-Versioned”) holds only current cases, supported by a Case History table. This requires less storage than DQB and enables new and resolved case counts over time.</p></td>
</tr>
<tr class="odd">
<td><p>Measure Table</p></td>
<td><p>Measure View</p></td>
<td><p>Similar in function. In TDQ the properties of measures are stored in their definition as xml, rather than a “measure table”. The Measurement View dynamically finds measurement views by their name, extracts the metadata, and returns a list. This makes measures easier to manage and more portable.</p></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p>Run</p></td>
<td><p>Queue</p></td>
<td><p>in DQB a “Run” executed all enabled measures and collected the results. A Run procedure started and remained running until all measures completed, or a fatal or unhandled exception occurred, at which point the “Run” exited.</p>
<p>The DQB “Run Table” along with “Run Steps” kept track of Runs and the measures included in that Run.</p>
<p>DQB was design to execute a “Run” for <u>all</u> measures once a day on a schedule, although multiple runs a day were theoretically possible. Runs would need to be manually triggered if a Run failed.</p>
<p>TDQ instead uses the Native SQL Server Service Broker Queue. Measurement jobs are periodically added to the schedule by an SQL Agent Job according to a set of rules. Measurement jobs are then run in parallel.</p>
<p>TDQ is design to run continuously and does not require special considerations around timing and scheduling</p></td>
</tr>
<tr class="even">
<td><p>Run Procedure</p></td>
<td><p>Schedule Procedure</p></td>
<td><p>DQB’s run procedure adds all measures to a run, then iterates through each measure until complete, before exiting. This can take minutes to hours.</p>
<p>TDQ’s schedule procedure checks the age of measurements and adds any needed measurement jobs to the queue and exits. This takes seconds. The measurement work is then performed in the background and in parallel.</p></td>
</tr>
<tr class="odd">
<td><p>Log Table</p></td>
<td><p>Log Table</p></td>
<td><p>Conceptually analogous, although the layout is different.</p></td>
</tr>
<tr class="even">
<td><p><em>N/A</em></p></td>
<td><p>Box Table</p></td>
<td><p>TDQ stores all of its configuration variables, code and table definitions in a “Box Table” allowing for easy deployment and migration between environments using a single “bootstrap script” automatically generated by the “Pack procedure”</p>
<p>DQB has no nothing like this, relying on traditional source script files and a .bat file for deployment automation.</p></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

# <sup><span id="AfV0wlxjL8"></span>Troubleshooting</sup>

*The server principal \<login> is not able to access the database
\<database> under the current security context.*

This can occur when a Measure View access another database. The precise
cause is not

understood, but may have something to do with Dynamic SQL execution. A
fix is to slightly reduce a level of security using the . This must be
applied to the database that hosts TDQ and the database included in the
Measure Query:

<sup>`ALTER DATABASE <TDQ host database> SET TRUSTWORTHY ON;`</sup>

<sup>`ALTER DATABASE <other database> SET TRUSTWORTHY ON;`</sup>

# <sup><span id="8YpiIad6bD"></span>Style</sup>

TDQ uses a consistent design and coding style.

## <sup><span id="NdAGYlFPRa"></span>Design Parsimony</sup>

-   TDQ has as few Tables as possible and does not follow third normal
    form. Category and type tables are avoided. This simplifies
    interpretation of table data, and query design.

-   Tables include the minimum data that must be persisted. Any data
    that can be derived, such as counts, is performed in views.

-   A minimum of programmable objects (stored procedures and functions)
    is included. Some common code is duplicated repeatedly (for example
    logging code), but this aids in readability.

-   Foreign key relationships are not included in the schema. Their
    utility is limited beyond placing undesirable constraints.

## <sup><span id="NfNWKCVUxA"></span>Naming Conventions</sup>

-   Object, Column and Variables names are CamelCase

-   Names are descriptive but concise, and make light use of
    abbreviations

-   The type of a variable is not included as part of its name

-   Naming follows a general-to-specific naming. For example, the
    reporting view for daily measurement statistics is
    “ReportMeasurementsDaily”, rather than DailyMeasurementReport. This
    helps in sorting and discovery.

-   Table and view names are either a noun like “Box” or “Log”, or use a
    plural for the item type they store, like “Measurements” and “Cases”

-   Primary and foreign key columns are prefixed with the table name
    e.g. CaseID

## <sup><span id="CWRBiRUqGm"></span>Coding Style</sup>

Due to the 4000 character limit imposed by the source code management
approach, coding style strikes a balance between being space efficient
but still readable.

-   <sup>Few empty line breaks are used, typically only to group major
    sections of code</sup>

-   <sup>Major comments are made as PRINT statements, to aide in
    debugging.SQL specific</sup>

-   <sup>All statements are semicolon terminated</sup>

-   <sup>Syntactic sugar such as “AS” in type declarations and join
    aliases is typically avoided</sup>

-   <sup>For aliased and calculated columns in queries, the column name
    followed by ‘=’ and the calculation statement is used, as opposed to
    putting the alias last. E.g. “SELECT ColumnName =1+1;”, vs. “SELECT
    1+1 AS ColumnName;”</sup>

-   <sup>Variables are declared as late as possible as close to the code
    that uses them, rather than in a big block at the top</sup>

-   <sup>Variable declaration includes value assignment in a single
    line, where possible (e.g. “DECLARE @v int = 1;”</sup>

-   <sup>Variable type names, assignments, join predicates, are tab
    aligned when they appear in subsequent lines</sup>

-   <sup>nvarchar is always used in preference to varchar, except where
    mandated</sup>

-   <sup>datetimeoffset is always used in preference to other date and
    time types, except where datetime2 is mandated (e.g. Temporal table
    system time columns)</sup>
