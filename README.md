# CatHerd Tactical DQ

Tactical DQ is a lightweight data quality monitoring framework fully contained within an instance of Microsoft SQL Server. The intended use case is where there is little to no existing master data management framework, and a simple low overhead throwaway tool is needed to start monitoring data quality. Typical scenarios are implementing a new reporting data store, or to support data migration as part of an ERP implementation. It is not intended to be a robust fully featured data quality solution.

## Key Features

- **Parallel background job management**. Uses SQL Server’s native Message Queues and Service Broker to manage measurement tasks as parallel background jobs, in conjunction with SQL Server Agent for scheduling.
- **Point-in-time history**: Uses SQL Server’s native Temporal “System-Versioned” table features to allow detailed progress reporting while minimising storage requirements.

- **Simple measure management**: Creating measures is simple and flexible, with embedded XML metadata for portability.

- **XML report generation**: Outputs XML formatted reporting and case lists for consumption directly into BI and reporting software, for storage as a file.

- **Single script setup**: Uses a single “bootstrap script” to deploy into a SQL server. No file management required.

- **Built-in source code management**: Maintains its own code repository within the database

- **Easy redeployment across environments**: Generates a bootstrap script for the current environment, on demand.

- **Email notifications**: Uses SQL Server’s native DB Mail to deliver notifications of changes to case lists and internal errors.

## Limitations

- Requires **SQL Server 2016** or later

- Requires **SQL Server Agent** and **Service Broker** enabled

- Email required **DB Mail** enabled with **Service Based Authentication** configured

- The TDQ maintainer will require **sysadmin** privileges on the SQL Server instance

## Installation

TDQ is installed using a “Bootstrap Script”. A Bootstrap Script can be generated by executing the `Pack` Procedure, which produces a *Bootstrap Script* as messages output.

The current version of a clean Bootstrap Script can be [downloaded here](bootstrap.sql).

The Bootstrap Script can then be executed on any database. There are two variables that could be altered first:

- **@SchemaName**: All TDQ objects will be created in this schema, except the Service Broker Service "Scheduler" and the SQL Agent "Scheduler". It’s recommended TDQ objects are isolated in their own schema, but `'dbo'` is an acceptable schema if this cannot be done.

- **@Prefix**: A prefix to the object name. All objects will have this text prefixed to their name. It’s not necessary to prefix TDQ objects if they are in their own schema, so an empty string is acceptable.

*Most* objects will take the name `{@SchemaName}.{@Prefix}{ObjectName}`
The Service Broker Service "Scheduler" will be named `{@Prefix}_{ObjectName}`
The SQL Agent Job "Scheduler" will be named `{Database Name}_{@SchemaName}_{@Prefix}_{ObjectName}`

### Examples:

| @SchemaName | @Prefix  | Object Name        |
|-------------|----------|--------------------|
| `'tdq'`     | `''`     | `tdq.Measures`     |
| `'dbo'`     | `'tdq\_'`| `dbo.tdq_Measures` |
| `'dbo'`     | `'dq'`   | `dbo.dqMeasures`   |

Once the variables have been set, the Bootstrap Script can be executed. This is detailed in the design section under `BootstrapScript` Procedure

## Configuration

TDQ is configured using the *Box Table*. Objects with `ObjectType = ‘CONF’` contain configuration values.

## Add a Measure

Measures are views in SQL, augmented with an embedded XML metadata block. Create a view with the following pattern:

    CREATE OR ALTER VIEW [{HomeSchema}].[{HomePrefix}{MeasureViewPattern}]{unique token} AS
    /*<measure>
    <id>{uniqueidentifier}</id>
    <code>{Measure Code}</code>
    <description>{Description of measure}</description>
    <refreshPolicy>{Continuous|Hourly|Daily|Mo|Tu|We|Th|Fr|Sa|Su}</description>
    <refreshTimeOffset>{HH:mm}</description>
    </measure>*/
    SELECT Column
    FROM Table
    WHERE Column=Value;

Where in the name of the view:

-  *{HomeSchema}*, *{HomePrefix}* and *{MeasureViewPattern}* are the configuration parameters in the Box table.

    > :warning: Warning
    > 
    > The schema, and the name of the view **must** be encapsulated with square brackets, such as \[schema\].\[full name of view\].
    > This is not strictly required for TSQL, but is required by the `Pack` Procedure and `Unpack` Procedure.
        
-   *{unique token}* is anything that makes the view name unique,
    such as a measure code. This has no impact on operation and reporting.

Take special note of the XML embedded in a comment. This is metadata that is required by TDQ:

> :warning: Warning
> 
> tags are `<caseSensitive>`

- `<id>{uniqueidentifier}</id>` stands for a GUID to track the measure even if the Measure Code changes. Use may the TSQL function `PRINT NEWID()` to generate one.

- `<code>{Measure Code}</code>` stands for the unique organisation meaningful measure code

- `<description>{Description of measure}</description>` stands for a organisation meaningful description of the data quality problem identified by the measure.

- `<refreshPolicy>` and `<refreshTimeOffset>` control the frequency and timing at which measurements are taken. See details below.

<<<<<<< HEAD
#### Refresh Policy

The *Refresh Policy* and *Time Offset* are used to schedule measurement jobs. When the scheduling agent job runs, measures that meet the conditions determined by the combination of refresh policy and time offset will be scheduled. In this way define the *earliest* time at which a measurement will be taken. The precise time will depend on the scheduling agent job.

| Refresh Policy             | Time Offset Meaning   | Description                                                                                                    |
|----------------------------|-----------------------|----------------------------------------------------------------------------------------------------------------|
| Hourly                     | Minutes past the hour | A new measurement will be taken each hour, but no earlier than the number of minutes past the hour.            |
| Daily                      | Time of day           | A new measurement will be taken each day, but no earlier than the time of day                                  |
| Mo, Tu, We, Th, Fr, Sa, Su | Time of day           | A new measurement will be taken once a week on the given day, no earlier than the given time of day.           |
| Continuous                 | Minimum wait time     | A new measurement will be taken once the time since the last measurement is greater than the minimum wait time |

Typical scenarios

| Scenario                                                                                                                                                                                                                                                                             | Refresh Policy | Time Offset |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------|-------------|
| Measurement is taken on a production data copy that is refreshed overnight. The measurement should be taken after source data refresh before business hours.                                                                                                                         | Daily          | 06:00       |
| Measurement is taken from a production copy of a particularly large source data is only refreshed on the weekend. Measurement should be taken early in the morning to ensure it’s ready before business hours.                                                                       | Monday         | 03:00       |
| Measurement is taken on a data warehouse that is progressively refreshed multiple times a day, and frequent quality measurement is desired. To ensure a load of jobs do not stack up on the hour, the measurement refresh should be delayed until at least 15 minutes after the hour | Hourly         | 00:15       |
| Measurement is taken on a near real-time copy of production                                                                                                                                                                                                                          | Continuous     | 00:30       |
| A measurement should be taken at least every 12 hours, regardless of the time of day.                                                                                                                                                                                                | Continuous     | 12:00       |
> :warning: Warning
>
> The Refresh policies Hour, Daily, and Mon-Sun do not “catch up”. Read the next section carefully!

Because the refresh policy and time offset does not determine precisely when a measurement will be taken, some combinations can lead to measures not being taken even when they are expected to be. This is because the refresh policy and time offset effectively define a *time window*. If that time window has passed, the `Schedule` Procedure will not schedule a measurement if the *time window* closes. There is no built-in "catch up". Some example scenarios follow:

- With `<refreshPolicy>Daily</refreshPolicy>` and `<refreshTimeOffset>23:30</refreshTimeOffset>`, if the server was rebooted just before 11:30pm and did not completely start up > until after 12am, the window has closed. The next measurement attempt would be after 11:30pm.

- With `<refreshPolicy>Sun</refreshPolicy>` and `<refreshTimeOffset>03:00</refreshTimeOffset>`, if the measurement was returning an error which was not resolved until Monday, the  measurement would not be reattempted until the following Sunday morning.

- With `<refreshPolicy>Hourly</refreshPolicy>` and `<refreshPolicy>00:45</refreshPolicy>`, If the scheduling agent job only runs the `Schedule` Procedure every 30 minutes then a measurement will **never be taken** because the check will be performed at 30 minutes past the hour too early, then again on the hour which is too late for last hour and too early for the current hour

- :no_entry: With `<refreshPolicy>Hourly</refreshPolicy>` and `<refreshTimeOffset>01:00</refreshTimeOffset>` or greater, a **measurement will never be taken**. This is because the interpretation is "Every hour, one hour past the hour".

By contrast `<refreshPolicy>Continuos</refreshPolicy>` always “catches up”. Regardless of when the last successful refresh was, as it was at least as `<refreshTimeOffset>` minutes ago a new measurement will be reattempted.

# Design

## Main Loop

The main loop of TDQ is as follows:

1. The *Scheduler Agent Job* executes the `Schedule` Procedure
2. The `Schedule` Procedure uses the `Measures` View and `Measurements` Table to determine which measurements to refresh.
    1. Technically this is done by starting a “Conversation” on the *Scheduler Service*
    2. The `Measures` View calculates the earliest refresh date and time using the `<refreshPolicy>` and `<refreshTimeOffset>`.
    3. If the earliest refresh date is in the past, a measurement refresh job “Message” is added to the *MeasurementJobs Queue*
2. When an message is added to the *MeasurementJobs Queue*, the 1RefreshFromQueue1 Procedure is executed
    1. The *RefreshFromQueue Procedure* takes the next job off the `MeasurementJobs` Queue and fires the `Refresh` Procedure
    2. If there are more messages in the queue, the *RefreshFromQueue Procedure* will be executed again within an interval of approximately five seconds, to a set maximum limit of simultaneous executions set by the `MaxParallelMeasurements` configuration parameter (in the `Box` Table)

## Objects

### `Box` Table

The Box Table stores configuration parameters, core object definitions, and measure viewsl referred to generically as "Objects"

| Column | Type | Usage and Interpretation
|--------|------|----
| `ObjectName` | `nvarchar(128)`, Primary Key | The name of the object, used to locate it in the table.
| `ObjectType` | `char(4)`. | One of four values:<br><br>`CONF`: Configuration parameter. The value is stored in one of the *Definition* columns.<br>`CODE`: Stored procedure, function or view definition script, *compressed*[^1] and stored in `DefinitionBinary`<br>`TABL`: Table definition script, , *compressed*[^1] and stored in `DefinitionBinary`<br>`MESR`: A measure view definition, *compressed*[^1] and stored in `DefinitionBinary`
| `ObjectSequence` | `tinyint` | Relevant for `CONF` and `TABL` objects. The ascending order in which objects must be created. This is used by the `Unpack` Procedure. `CONF` items, the `Box` Table and the `Unpack` procedure have an `ObjectSequence` of `0` and are ignored by the `Unpack` Procedure.
| `DefinitionBinary` | `varbinary(8000)` | Used by `CODE`, `TABL` and `MESR` objects to store their definitions.
| `DefinitionText`<br>`DefinitionDecimal`<br>`DefinitionDate`<br>`DefinitionBit` | `nvarchar(4000)`<br>`decimal(19,5)`<br>`datetimeoffset(0)`<br>`bit`<br>All nullable | Used by `CONF` objects to store their values.

[^1] *Compressed* means passed through SQL Server function `COMPRESS()`

### `Measurements` Table

A record of each measure refresh. Rows are added to this table by the `Refresh` Procedure, and used by the `ReportMeasureDetail` View to provide a detailed accounting of case counts. This table should only contain rows of successful refreshes. Refreshes that ended in failure should not be in this table.

| Column | Type | Usage and Interpretation
|--------|------|----
| `MeasurementID` | `int`, Primary Key, identity | Automatically generated unique sequence number for the measurement.
| `MeasureID` | `uniqueidentifier` | Reference to the measure itself. Joins to the `Measures` View
| `TimestampStarted` | `datetimeoffset(0)` default `SYSDATETIMEOFFSET()` | The date and time the measure refresh started.
| `TimestampCompleted` | `datetimeoffset(0)` nullable | The date and time the measure refresh was completed. When this is `NULL`, it means the measure refresh is still in progress, or that the refresh failed but the exception handler failed to delete the row. Because there is no guarantee, this table should not be used to determine which measures are currently being refreshed.

### `Cases` Table

A row for each row returned by the measure view, the last time it was refreshed. Each case row is a set of properties and values which can be used to locate the record that failed the data quality conditions programmed into the measure view, in a system of record.

This table contains only *current* cases. The `CaseHistory` Table retains a full history. This is a **Temporal Table**, also known as *System-Versioned*. Any rows updated or deleted are automatically copied to the *History* table.

| Column | Type | Usage and Interpretation
|--------|------|----
| `CaseID` | `int` Primary Key identity | Automatically generated unique sequence number for the *case*.
| `MeasureID` | `uniqueidentifier` | Reference to the *measure* to which this *case* related. Joins to the `Measures` View
| `MeasurementID` | `int` | Reference the `Measurements` Table row, from which the `TimestampStarted` and `TimestampCompleted` columns can be retrieved
| `CaseProperty1` ... `CaseProperty9` | `nvarchar(128)` nullable[^1] | The name of the measure view column from which the related `CaseValue1` ... `CaseValue9` value was obtained
| `CaseValue1` ... `CaseValue9` | `nvarchar(4000)` nullable | The value returned by measure view, from the column named in the related `CaseProperty1` ... `CaseProperty9`
| `CasePropertiesExtended` | `nvarchar(4000)` nullable | A concatenation of columns and column values beyond the 9th, or as much will fit in 4000 characters. Takes format `Name10=Value10;Name11=Value11...`
| `CaseChecksum` | `int` | The checksum value of the row from the measure view[^2].
| `Identified` | `datetime2(0)` | The UTC date and time when the record was created. This is automatically set, and is part of the temporal table definition
| `Resolved` | `datetime2(0)` | Part of the temporal table definition, gets automatically and permanently set to `9999-12-31 23:59:59`. This does not have a meaningful interpretation in the `Cases` Table, other than the simple meaning that the case is still current. There is a matching column in the `CaseHistory` which is set when a case is updated or deleted. 

[^1] Except `CaseProperty1` and `CaseValue1`. The Measure View should return at least one column of data, or it's not possible to locate the offending record in the system of record.

[^2] Uses the SQL function `BINARY_CHECKSUM()`
	> :information_source: Row checksum is from the measure view, **not** the `Cases` Table. Running `BINARY_CHECKSUM()` on the `Cases` Table will probably not get the same result due to type conversion and the `CasePropertiesExtended` column for views with 10+ columns.


### `CaseHistory` Table

TODO: Complete

### `Log` Table

TODO: Complete

### Refresh Procedure

The `Refresh` Procedure takes a Measure `<id>` (uniqueidentifier) or Measure `<code>`, selects all rows returned by the associated SQL View, and stores the results. The process is as follows:

1. Look up the details of the supplied `@MeasureID` or `@MeasureCode` in the `Measures` View. Specifically the name of the *measure view*
2. `SELECT *` from the *measure view* into a temporary table
2. Merges the temporary table into the `Cases` table.
    - New Cases are added
    - Cases in the `Cases` Table but not the *measure view* are deleted.
> :information_source:
>
> The `Cases` Table is a Temporal (System-Versioned) table. A full history is retained. See details in the **Cases Table** section.

### Bootstrap Script

The *Bootstrap Script* installs and configures the TDQ framework in the following steps:

1. Set the `@SchemaName` and `@Prefix` variables. These are where the framework will be installed.       
    > :warning: Ensure TDQ is isolated
    >
    > To ensure there are no collisions with existing objects, set at least one of `@SchemaName` and `@Prefix` variables. The `Pack` Procedure will assume **any objects meeting this pattern** are TDQ objects, which will have deterimental consequences if incorrect.
2. If the `Box` Table already exists, throw an error and exit
3. Create a temporary table `#BoxTable` and insert all the TDQ objects into it
4. Reteieves the the `Box` Table create script in `#BoxTable` and executes it
5. Inserts the content of `#BoxTable` into the `Box` Table
6. Reteieves the `Unpack` Procedure create script in `#BoxTable` and runs it
7. Executes the `Unpack` Procedure. This creates all the TDQ objects and executes configuration procedures. See details in the **Unpack Procedure** section.
    
### Unpack Procedure

The `Unpack` Procedure reteieves TDQ object create scripts from the `Box` Table and executes them. Auto-executing procedures, such as `AgentConfig` procedure are also executed after creation. The procedure is as follows:

1. Retrieve all `BinaryContent` for Objects in the `Box` Table with `ObjectType IN ('CODE','TABL','MESR')`
2. Decompress and execute each Object according to the `Sequence`
3. Any objects with `<autoExecute>true<autoExecute>` in their XML metadata are executed

# Comparison to “DQ-in-a-Box” (DQB)

"DQ-in-a-Box" is a Deloitte owned project for a lightweight data quality monitoring framework. CatHerd Tactical DQ is inspired by this work.

|DQB Concept   |TDQ Concept  |Commentary
|--------------|-------------|------------
|Measure       |Measure      |Conceptually the same, although measures in TDQ are all views. Additionally, there is no prescribed column layout in TDQ.
|Run Steps     |Measurement  |DQB’s run steps table gave a count history for measures, similar to TDQ’s Measurement table.<br><br>Semantically, TDQ refers to the activity of searching for data quality issues as “taking a measurement”, compared to DQB’s “running a measure”.
|Results       |Cases        |Conceptually analogous. <br><br>However in TDQ, the Cases Table is a Temporal Table (aka “System-Versioned”) holds only current cases, supported by a Case History table. This requires less storage than DQB and enables new and resolved case counts over time.
|Measure Table |Measure View |Similar in function. In TDQ the properties of measures are stored in their definition as xml, rather than a “measure table”. The Measurement View dynamically finds measurement views by their name, extracts the metadata, and returns a list. This makes measures easier to manage and more portable.
|Run           |Queue        |In DQB a “Run” executed all enabled measures and collected the results. A Run procedure started and remained running until all measures completed, or a fatal or unhandled exception occurred, at which point the “Run” exited.<br><br>The DQB “Run Table” along with “Run Steps” kept track of Runs and the measures included in that Run. <br><br>DQB was design to execute a “Run” for all measures once a day on a schedule, although multiple runs a day were theoretically possible. Runs would need to be manually triggered if a Run failed.<br><br>TDQ instead uses the Native SQL Server Service Broker Queue. Measurement jobs are periodically added to the schedule by an SQL Agent Job according to a set of rules. Measurement jobs are then run in parallel.<br><br>TDQ is design to run continuously and does not require special considerations around timing and scheduling
Run Procedure  |Schedule Procedure	|DQB’s run procedure adds all measures to a run, then iterates through each measure until complete, before exiting. This can take minutes to hours.<br><br>TDQ’s schedule procedure checks the age of measurements and adds any needed measurement jobs to the queue and exits. This takes seconds. The measurement work is then performed in the background and in parallel.
|Log Table     |Log Table    |Conceptually analogous, although the layout is different.
|N/A           |Box Table    |TDQ stores all of its configuration variables, code and table definitions in a “Box Table” allowing for easy deployment and migration between environments using a single “bootstrap script” automatically generated by the “Pack procedure” <br><br>DQB has no nothing like this, relying on traditional source script files and a .bat file for deployment automation.

# Troubleshooting

- *The server principal \<login> is not able to access the database \<database> under the current security context.*

    This can occur when a Measure View access another database. The precise cause is not understood, but may have something to do with Dynamic SQL execution. A fix is to slightly reduce a level of security using the . This must be applied to the database that hosts TDQ and the database included in the Measure Query:

    ```
    ALTER DATABASE <TDQ host database> SET TRUSTWORTHY ON;
    ALTER DATABASE <other database> SET TRUSTWORTHY ON;
    ```

# Style

TDQ uses a consistent design and coding style.

## Design Parsimony

- TDQ has as few Tables as possible and does not follow third normal form. Category and type tables are avoided. This simplifies interpretation of table data, and query design.
- Tables include the minimum data that must be persisted. Any data that can be derived, such as counts, is performed in views.
- A minimum of programmable objects (stored procedures and functions) is included. Some common code is duplicated repeatedly (for example logging code), but this aids in readability.
- Foreign key relationships are not included in the schema. Their utility is limited beyond placing undesirable constraints.

## Naming Conventions

- Object, Column and Variables names are `CamelCase`
- Names are descriptive but concise, and avoid abbreviations. Common initialisms such as ID or No. are still used.
- The type of a variable is not included as part of its name
- Naming follows a general-to-specific naming. For example, the reporting view for daily measurement statistics is “ReportMeasurementsDaily”, rather than DailyMeasurementReport. This helps in sorting and discovery.
- Table and view names are either a noun like “Box” or “Log”, or use a plural for the item type they store, like “Measurements” and “Cases”
- Primary and foreign key columns are prefixed with the table name e.g. `CaseID`

## Coding Style

Due to the 4000 character limit imposed by the source code management approach, coding style strikes a balance between being space efficient but still readable.
=======
-------
>>>>>>> 724e3327f6f798f74fcb2a9e348915eb031fb66a

For details on configuration, detailed usage, and architecture, see the [Wiki](https://github.com/davolsen/tacticaldq/wiki)
